# Big Data

## What is Big Data?

Big data is a term used to describe a collection of data that is huge in size and yet growing exponentially with time. It is so large and complex that traditional data management tools aren't able to store it nor process it efficiently. Some examples of big data include:

* **The New York Stock Exchange** which generates about one terabyte of new trade data per day.

* **Facebook** which generates over 500 terabytes of new data everyday. However, this is mostly generated in terms of photos, videos, messages, comments...

* **Jet engines** which can generate over 10 terabytes of data in just 30 minutes of flight time. With thousands of flights everyday, the data generated could be in the Petabytes.

Big data can also be defined by use of the four V's (sometimes including a fifth). These Vs are volume, variety, velocity, veracity, and sometimes value.

**Volume** 

The main characteristic that makes data "big" is the sheer volume. It makes no sense to focus on minimum storage units due to the total amount of information growing exponentially every year. 

**Variety** 

One of the most interesting developments in technology as more information is digitized. Traditional data types, or structured data, include things that fit neatly in a relational database. 

This structured data is augmented by unstructured data which is where things such as audio files, MRI images, web pages... are put. Essentially anything that can be captured and stored but doesnt have a *meta model* (a set of rules to frame a concept or idea — it defines a class of information and how to express it) that neatly defines it.

Unstructured data is a fundamental concept in big data. The best way to understand unstructured data is by comparing it to structured data. Think of *structured data* as data that follows a set of well defined rules, ie, money. Money is always numbers with two decimal points and a symbol which designates the currency.

With *unsturctured data* there are no rules. A picture, voice recording... can all be different but they express ideas and thoughts based on human understanding. One of the goals of big data is to take this unstructured data and make sense of it.

**Velocity**

This is the frequency of data that needs to be processed. For example, all the facebook messages being sent at the same time, or the credit card payments made on the same carrier every minute of every day. To do this, the data must be processed very quickly. A streaming application such as AWS Kinesis is an example of an application that handles the velocity of data.

**Veracity**

This refers to the trustworthiness and accuracy of the data. Can you be sure the data is representative? Is the data collected true?

**Value**

A real world objective is critical to the mashup of the four Vs. Will the insights gathered from analysis serve to create a cost cutting measure? Will it lead to the discovery of a critical causal effect that results in a cure to a disease? 

The ultimate objective of any big data project should be to generate some sort of value for the company doing all the analysis. Otherwise, you’re just performing some technological task for technology’s sake.